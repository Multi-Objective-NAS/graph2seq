{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import model_utils.configure as conf\n",
    "from model import Graph2Seq\n",
    "import utils\n",
    "\n",
    "import math\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "INPUT = 'input'\n",
    "CONV1X1 = 'conv1x1-bn-relu'\n",
    "CONV3X3 = 'conv3x3-bn-relu'\n",
    "MAXPOOL3X3 = 'maxpool3x3'\n",
    "OUTPUT = 'output'\n",
    "\n",
    "mode = \"train\"\n",
    "random.seed(conf.seed)\n",
    "np.random.seed(conf.seed)\n",
    "torch.manual_seed(conf.seed)\n",
    "logging.info(\"conf = %s\", conf)\n",
    "\n",
    "conf.source_length = conf.encoder_length = conf.decoder_length = (conf.nodes + 2) * (conf.nodes - 1) // 2\n",
    "epochs = conf.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model_utils' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ef3c5a4ed0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_utils' is not defined"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(model_utils.aggregators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import model_utils.configure as conf\n",
    "\"\"\"\n",
    "0: sos/eos\n",
    "1: no connection\n",
    "2: connection\n",
    "3: CONV1X1\n",
    "4: CONV3X3\n",
    "5: MAXPOOL3X3\n",
    "6: OUTPUT\n",
    "\"\"\"\n",
    "        \n",
    "class ControllerDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        super(ControllerDataset, self).__init__()\n",
    "\n",
    "        self.adjacency_matrices = []\n",
    "        self.operations = []\n",
    "        self.sequences = []\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "\n",
    "                jo = json.loads(line, object_pairs_hook=OrderedDict)\n",
    "\n",
    "                self.adjacency_matrices.append(jo['module_adjacency'])\n",
    "                self.operations.append(jo['module_operations'])\n",
    "                self.sequences.append(jo['sequence'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        operations = self.operations[index]\n",
    "        num_nodes = len(operations)\n",
    "\n",
    "        ops = []\n",
    "        for op in operations:\n",
    "            if op == CONV1X1:\n",
    "                ops.append(3)\n",
    "            elif op == CONV3X3:\n",
    "                ops.append(4)\n",
    "            elif op == MAXPOOL3X3:\n",
    "                ops.append(5)\n",
    "            elif op == OUTPUT:\n",
    "                ops.append(6)\n",
    "            if op == INPUT:\n",
    "                ops.append(7)\n",
    "\n",
    "        sample = {\n",
    "            'matrix' : torch.LongTensor(self.adjacency_matrices[index]),\n",
    "            'operations': torch.LongTensor(ops),\n",
    "            'sequence': torch.LongTensor(self.sequences[index])\n",
    "        }\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    ## transform into batch samples\n",
    "\n",
    "    ## create node -> global idnex\n",
    "    ## global index -> neighbor's global index\n",
    "\n",
    "    degree_max_size = conf.degree_max_size\n",
    "    graph_size = conf.graph_size\n",
    "    # degree_max_size = 5\n",
    "    # graph_size = 7\n",
    "    seq_max_length = int((graph_size+2)*(graph_size-1)/2)\n",
    "\n",
    "    g_idxs = []\n",
    "    g_fw_adjs = []\n",
    "    g_bw_adjs = []\n",
    "    g_operations = []\n",
    "    g_sequence = []\n",
    "    g_num_nodes = []\n",
    "\n",
    "    g_idx_base = 0\n",
    "    for g_idx, sample in enumerate(samples):\n",
    "        matrix = sample['matrix']\n",
    "        num_nodes = matrix.shape[0]\n",
    "        g_num_nodes.append(num_nodes)\n",
    "\n",
    "        for row in range(num_nodes):\n",
    "            g_fw_adjs.append(list())\n",
    "            g_bw_adjs.append(list())\n",
    "\n",
    "        for row in range(num_nodes):\n",
    "           for col in range(row+1, num_nodes):\n",
    "            if matrix[row][col] :\n",
    "                g_fw_adjs[g_idx_base + row].append(g_idx_base + col)\n",
    "                g_bw_adjs[g_idx_base + col].append(g_idx_base + row)\n",
    "\n",
    "        for op in sample['operations']:\n",
    "            g_operations.append(op)\n",
    "\n",
    "        sequence = sample['sequence']\n",
    "\n",
    "        sequence = torch.cat([sequence, torch.LongTensor([0] * (seq_max_length - len(sequence)))])\n",
    "        g_sequence.append(sequence)\n",
    "\n",
    "        g_idx_base += num_nodes\n",
    "\n",
    "    for idx in range(len(g_fw_adjs)):\n",
    "        g_fw_adjs[idx].extend([g_idx_base] * (degree_max_size - len(g_fw_adjs[idx])))\n",
    "        g_bw_adjs[idx].extend([g_idx_base] * (degree_max_size - len(g_bw_adjs[idx])))\n",
    "        \n",
    "    g_operations.append(0)\n",
    "\n",
    "    g_num_nodes = torch.LongTensor(g_num_nodes)\n",
    "\n",
    "    # [batch_size, conf.degree_max_size]\n",
    "    g_fw_adjs = torch.LongTensor(g_fw_adjs)\n",
    "    g_bw_adjs = torch.LongTensor(g_bw_adjs)\n",
    "\n",
    "    # [batch_size +1] # due to padding\n",
    "    g_operations = torch.LongTensor(g_operations)\n",
    "\n",
    "    # [sum of sequence_length]\n",
    "    g_sequence = torch.stack(g_sequence)\n",
    "    print(\"g_fw_adjs size: {}\".format(g_fw_adjs.size()))\n",
    "    print(\"g_bw_adjs.size() : {}\".format(g_bw_adjs.size()))\n",
    "    print(\"num_nodes.size() : {}\".format(num_nodes.size()))\n",
    "    print(\"operation.size() : {}\".format(operation.size()))\n",
    "    print(\"operation.size() : {}\".format(operation.size()))\n",
    "\n",
    "    return {\n",
    "            'num_nodes' : g_num_nodes,\n",
    "            'fw_adjs': g_fw_adjs,\n",
    "            'bw_adjs': g_bw_adjs,\n",
    "            'operations': g_operations,\n",
    "            'sequence': g_sequence\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from layers import Layer, Dense\n",
    "from inits import glorot, zeros\n",
    "\"\"\"\n",
    "\n",
    "class tMeanAggregator(nn.Module):\n",
    "    \"\"\"Aggregates via mean followed by matmul and non-linearity.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, neigh_input_dim=None,\n",
    "            dropout=0, withBias=True, act=F.relu,\n",
    "            concat=False, mode=\"train\", **kwargs):\n",
    "        super(tMeanAggregator, self).__init__(**kwargs)\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.withBias = withBias\n",
    "        self.act = act\n",
    "        self.concat = concat\n",
    "        self.mode = mode\n",
    "\n",
    "        \n",
    "        if neigh_input_dim == None:\n",
    "            neigh_input_dim = input_dim\n",
    "\n",
    "        if concat:\n",
    "            self.output_dim = 2 * output_dim\n",
    "\n",
    "        self.neigh_weights = nn.init.xavier_uniform_(torch.empty(neigh_input_dim, output_dim))\n",
    "        self.self_weights = nn.init.xavier_uniform_(torch.empty(input_dim, output_dim))\n",
    "        \n",
    "        if self.withBias:\n",
    "            self.bias = torch.zeros(self.output_dim)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, self_vecs, neigh_vecs, neigh_len=0):\n",
    "        if self.mode == \"train\":\n",
    "            neigh_vecs = F.dropout(neigh_vecs, self.dropout)\n",
    "            self_vecs = F.dropout(self_vecs, self.dropout)\n",
    "\n",
    "        # reduce_mean performs better than mean_pool\n",
    "        neigh_means = torch.mean(neigh_vecs, dim=1)\n",
    "        # neigh_means = mean_pool(neigh_vecs, neigh_len)\n",
    "\n",
    "        # [nodes] x [out_dim]\n",
    "        from_neighs = torch.matmul(neigh_means, self.neigh_weights)\n",
    "        from_self = torch.matmul(self_vecs, self.self_weights)\n",
    "\n",
    "        if not self.concat:\n",
    "            output = torch.add(from_self, from_neighs)\n",
    "        else:\n",
    "            output = torch.cat([from_self, from_neighs], dim=1)\n",
    "\n",
    "        # bias\n",
    "        if self.withBias:\n",
    "            output += self.bias\n",
    "\n",
    "        return self.act(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "enmbeded_node_rep : torch.Size([15, 16])\nhop: 0, after aggregate: fw_hidden_size: torch.Size([14, 32])\nhop: 1, after aggregate: fw_hidden_size: torch.Size([14, 32])\nbw_hidden_size torch.Size([14, 32])\nhop: 2, after aggregate: fw_hidden_size: torch.Size([14, 32])\nbw_hidden_size torch.Size([14, 32])\nhop: 3, after aggregate: fw_hidden_size: torch.Size([14, 32])\nbw_hidden_size torch.Size([14, 32])\nhop: 4, after aggregate: fw_hidden_size: torch.Size([14, 32])\nbw_hidden_size torch.Size([14, 32])\nhop: 5, after aggregate: fw_hidden_size: torch.Size([14, 32])\nbw_hidden_size torch.Size([14, 32])\nafter relu hidden : torch.Size([2, 7, 64])\npooled : torch.Size([2, 64])\npooled : tensor([[0.0189, 0.1014, 0.0000, 0.0799, 0.0310, 0.0669, 0.0000, 0.1275, 0.0465,\n         0.1214, 0.0595, 0.1352, 0.0496, 0.0376, 0.0006, 0.1255, 0.0000, 0.0397,\n         0.0000, 0.0234, 0.0000, 0.0056, 0.0101, 0.0209, 0.0000, 0.0000, 0.0000,\n         0.0448, 0.0000, 0.0706, 0.0000, 0.0000, 0.0829, 0.0521, 0.0659, 0.0000,\n         0.0350, 0.0452, 0.0302, 0.0000, 0.0000, 0.0815, 0.0212, 0.0422, 0.0398,\n         0.0424, 0.0664, 0.0295, 0.0000, 0.0169, 0.0273, 0.0000, 0.0374, 0.0000,\n         0.0148, 0.0323, 0.0086, 0.0000, 0.0107, 0.0004, 0.0319, 0.0000, 0.0000,\n         0.0154],\n        [0.0290, 0.0847, 0.0000, 0.0971, 0.0420, 0.0503, 0.0000, 0.1220, 0.0341,\n         0.1214, 0.0436, 0.1567, 0.0549, 0.0376, 0.0006, 0.1605, 0.0000, 0.0305,\n         0.0000, 0.0193, 0.0000, 0.0075, 0.0101, 0.0194, 0.0000, 0.0000, 0.0000,\n         0.0358, 0.0000, 0.0521, 0.0000, 0.0000, 0.0505, 0.0321, 0.0591, 0.0000,\n         0.0350, 0.0334, 0.0302, 0.0000, 0.0000, 0.0363, 0.0097, 0.0057, 0.0320,\n         0.0398, 0.0664, 0.0295, 0.0000, 0.0147, 0.0271, 0.0023, 0.0288, 0.0000,\n         0.0122, 0.0251, 0.0035, 0.0000, 0.0089, 0.0003, 0.0241, 0.0029, 0.0000,\n         0.0144]], grad_fn=<MaxBackward0>)\n\ngrphaph_embedding: torch.Size([2, 64])\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'grphaph_embedding' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-dc4728195357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0men\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfw_adjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_adjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/g2s/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-6821de541621>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, fw_adjs, bw_adjs, features, num_nodes)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grphaph_embedding: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrphaph_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;31m# graph_embedding = LSTMStateTuple(c=graph_embedding, h=graph_embedding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mgraph_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grphaph_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "import model_utils.configure as conf\n",
    "\n",
    "en = Encoder(\"train\", conf.vocab_size, conf.hidden_layer_dim, \"bi\", 6, True, conf.dropout, conf.learning_rate)\n",
    "\n",
    "i = 0\n",
    "for step, sample in enumerate(queue):\n",
    "    fw_adjs = sample['fw_adjs'] \n",
    "    bw_adjs = sample['bw_adjs'] \n",
    "    operations = sample['operations'] \n",
    "    num_nodes = sample['num_nodes'] \n",
    "    sequence = sample['sequence'] \n",
    "\n",
    "    en(fw_adjs, bw_adjs, operations, num_nodes)\n",
    "    break\n",
    "    i+=1\n",
    "    if i == 1: break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# model = Graph2Seq(mode=mode, conf=conf)\n",
    "\n",
    "# load data\n",
    "# dataset = ControllerDataset(conf.data_file_path)\n",
    "queue = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, pin_memory=False, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}