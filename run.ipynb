{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import model_utils.configure as conf\n",
    "from model import Graph2Seq\n",
    "import utils\n",
    "\n",
    "import math\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "INPUT = 'input'\n",
    "CONV1X1 = 'conv1x1-bn-relu'\n",
    "CONV3X3 = 'conv3x3-bn-relu'\n",
    "MAXPOOL3X3 = 'maxpool3x3'\n",
    "OUTPUT = 'output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\"\n",
    "random.seed(conf.seed)\n",
    "np.random.seed(conf.seed)\n",
    "torch.manual_seed(conf.seed)\n",
    "logging.info(\"conf = %s\", conf)\n",
    "\n",
    "conf.source_length = conf.encoder_length = conf.decoder_length = (conf.nodes + 2) * (conf.nodes - 1) // 2\n",
    "epochs = conf.epochs\n",
    "\n",
    "# model = Graph2Seq(mode=mode, conf=conf)\n",
    "\n",
    "# load data\n",
    "#dataset = utils.ControllerDataset(conf.data_file_path, conf.graph_size)\n",
    "#queue = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, pin_memory=False)\n",
    "# queue = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# del dataset\n",
    "# data_file_path = \"data/train_data.json\"\n",
    "# dataset = utils.ControllerDataset(conf.data_file_path)\n",
    "queue = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, pin_memory=False, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(train_queue, optimizer):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    nll = utils.AvgrageMeter()\n",
    "    print(\"train_queue {}\".format(train_queue))\n",
    "    for step, sample in enumerate(train_queue):\n",
    "        fw_adjs = sample['fw_adjs']\n",
    "        bw_adjs = sample['bw_adjs']\n",
    "        operations = sample['operations']\n",
    "        sequence = sample['sequence']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        log_prob, predicted_value = model(fw_adjs, bw_adjs, operations, targets=sequence)\n",
    "        loss = F.nll_loss(log_prob.contiguous().view(-1, log_prob.size(-1)), sequence.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), conf.grad_bound)\n",
    "        optimizer.step()\n",
    "        \n",
    "        n = sequence.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        nll.update(loss.data, n)\n",
    "\n",
    "    return objs.avg, nll.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "logging.info('Train data: {}'.format(len(queue)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=conf.lr, weight_decay=conf.l2_reg)\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "for epoch in range(2):\n",
    "    loss, ce = train_step(queue, optimizer)\n",
    "    print(\"epoch %04d train loss %.6f ce %.6f\", epoch, loss, ce)\n",
    "    # logging.info(\"epoch %04d train loss %.6f ce %.6f\", epoch, loss, ce)\n",
    "\n",
    "## save trainable parameters\n",
    "torch.save(model.state_dict(), conf.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model_utils.aggregators import MeanAggregator\n",
    "import model_utils.configure as conf\n",
    "import utils\n",
    "\n",
    "from decoder import Decoder\n",
    "from encoder import Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, mode, conf):\n",
    "        super(Graph2Seq, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "        self.l2_lambda = conf.l2_lambda\n",
    "        self.feature_embedding_dim = conf.hidden_layer_dim\n",
    "        self.vocab_size = conf.vocab_size\n",
    "        self.length = conf.vocab_size -1\n",
    "        self.hop_size = conf.hop_size\n",
    "\n",
    "        # the setting for the GCN\n",
    "        self.graph_encode_direction = conf.graph_encode_direction\n",
    "        self.concat = conf.concat\n",
    "\n",
    "        # the setting for the decoder\n",
    "        self.single_graph_nodes_size = conf.graph_size\n",
    "        self.attention = conf.attention\n",
    "        self.decoder_layers = conf.decoder_layers\n",
    "\n",
    "        self.dropout = conf.dropout\n",
    "        self.learning_rate = conf.learning_rate\n",
    "\n",
    "        self.if_pred_on_dev = False\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "                                mode=mode,\n",
    "                                vocab_size=self.vocab_size,\n",
    "                                feature_embedding_dim=self.feature_embedding_dim,\n",
    "                                graph_encode_direction=self.graph_encode_direction,\n",
    "                                hop_size=self.hop_size,\n",
    "                                concat=self.concat,\n",
    "                                dropout=self.dropout,\n",
    "                                learning_rate=self.learning_rate\n",
    "                                )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "                                mode=mode,\n",
    "                                hidden_dim=self.feature_embedding_dim,\n",
    "                                vocab_size=self.vocab_size,\n",
    "                                dropout=self.dropout,\n",
    "                                length=self.length,\n",
    "                                layers=self.decoder_layers\n",
    "                                )\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        encoder, decoder가 공유해야하는 것 : node feature embedding -> should it?\n",
    "        encoder에서는 operation이 ndoe feature\n",
    "        decoder에서는 operation + connection 이 node feature\n",
    "        seminas에서는 다른 embedding 이용\n",
    "        graph2sec 에서는 동일한 embedding 이용\n",
    "        나는 다르게 써야겠당\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, fw_adjs, bw_adjs, operations, targets=None):\n",
    "        encoded_nodes, graph_embedding = self.encoder(fw_adjs, bw_adjs, operations)\n",
    "        # check dimension\n",
    "        decoder_input = torch.cat([graph_embedding, targets], dim=1)\n",
    "        predicted_softmax, decoded_ids = self.decoder(graph_embedding, targets=targets)\n",
    "\n",
    "        return predicted_softmax, decoded_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, mode, conf):\n",
    "        super(Graph2Seq, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "        self.l2_lambda = conf.l2_lambda\n",
    "        self.feature_embedding_dim = conf.hidden_layer_dim\n",
    "        self.vocab_size = conf.vocab_size\n",
    "        self.length = conf.vocab_size -1\n",
    "        self.hop_size = conf.hop_size\n",
    "\n",
    "        # the setting for the GCN\n",
    "        self.graph_encode_direction = conf.graph_encode_direction\n",
    "        self.concat = conf.concat\n",
    "\n",
    "        # the setting for the decoder\n",
    "        self.single_graph_nodes_size = conf.graph_size\n",
    "        self.attention = conf.attention\n",
    "        self.decoder_layers = conf.decoder_layers\n",
    "\n",
    "        self.dropout = conf.dropout\n",
    "        self.learning_rate = conf.learning_rate\n",
    "\n",
    "        self.if_pred_on_dev = False\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "                                mode=mode,\n",
    "                                vocab_size=self.vocab_size,\n",
    "                                feature_embedding_dim=self.feature_embedding_dim,\n",
    "                                graph_encode_direction=self.graph_encode_direction,\n",
    "                                hop_size=self.hop_size,\n",
    "                                concat=self.concat,\n",
    "                                dropout=self.dropout,\n",
    "                                learning_rate=self.learning_rate\n",
    "                                )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "                                mode=mode,\n",
    "                                hidden_dim=self.feature_embedding_dim,\n",
    "                                vocab_size=self.vocab_size,\n",
    "                                dropout=self.dropout,\n",
    "                                length=self.length,\n",
    "                                layers=self.decoder_layers\n",
    "                                )\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        encoder, decoder가 공유해야하는 것 : node feature embedding -> should it?\n",
    "        encoder에서는 operation이 ndoe feature\n",
    "        decoder에서는 operation + connection 이 node feature\n",
    "        seminas에서는 다른 embedding 이용\n",
    "        graph2sec 에서는 동일한 embedding 이용\n",
    "        나는 다르게 써야겠당\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, fw_adjs, bw_adjs, operations, targets=None):\n",
    "        encoded_nodes, graph_embedding = self.encoder(fw_adjs, bw_adjs, operations)\n",
    "        # check dimension\n",
    "        decoder_input = torch.cat([graph_embedding, targets], dim=1)\n",
    "        predicted_softmax, decoded_ids = self.decoder(graph_embedding, targets=targets)\n",
    "\n",
    "        return predicted_softmax, decoded_ids"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}